# omnivore-export

This is an export script for the
[Omnivore](https://github.com/omnivore-app/omnivore)
read-it-later solution written in Python.

Its main purpose was to create a backup of all links saved in Omnivore,
as long as the Omnivore app still lacked an export function.

Since Omnivore also lacked functionality to show the number of articles,
this repository also provides a script to show these numbers.

Meanwhile, Omnivore provides a way to export the links in the web UI
via the menu option "Settings" - "Export Data", so that the export script
is not really needed any more.

But unfortunately, the Omnivore team decided to
[shut down](https://blog.omnivore.app/p/details-on-omnivore-shutting-down)
the service in November 2024 and recommends using
[Readwise](https://readwise.io/) (paid service) or
[Wallabag](https://wallabag.org/) (open-source) instead.

While Readwise has released
an [Omnivore importer](https://x.com/ReadwiseReader/status/1851426417684193527),
Wallabag was initially lacking such a feature.

Therefore, this repository also contains a script to convert the exported
links from Omnivore to the import format of Wallabag v2.

Meanwhile, Wallabag also
[integrated](https://github.com/wallabag/wallabag/pull/7754) a function
to import from Omnivore, which will be available in version 2.6.10 of Wallabag
and can be already used in the hosted solution,
so that this script is not needed any more either.

## Export and summary scripts

### Prerequisites

To run this script, you need to install
[gql](https://github.com/graphql-python/gql) with httpx support first:

```sh
pip install --pre -U gql[httpx]
```

Next, you must
[create an API key for Omnivore](https://omnivore.app/settings/api).

Then, change the global variable `API_KEY`
in the script `omnivore-export.py`,
or set the environment variable `OMNIVORE_API_KEY`.

If you're not using the free hosted Omnivore,
you must also change the global variable `API_URL`
or set the environment variable `OMNIVORE_API_URL`.

### Other options

You can change the path for the exported data
with the global variable `BACKUP_PATH`
or the environment variable `OMNIVORE_BACKUP_PATH`.
The current date is automatically added to the backup filename,
unless you change the global variable `WITH_DATE` to False
or set the environment variable `OMNIVORE_WITH_DATE` to `no`.

There are some more global variables that you can change in the script:

- `SEARCH = "in:all"` - change if you don't want to export everything
- `LIMIT = 100` - the batch size when querying the API (max. 100)
- `TIMEOUT = 15` - the request timeout in seconds when querying the API
- `WITH_CONTENT = False` - change if you want to export the content as well

### Running the script

Finally, just run the script via Python:

```sh
python omnivore-export.py 
```

### Data store summary

This repository also contains a script `omnivore-summary.py`
that can be used to print a summary of the data store in Omnivore.

After configuring it in the same way as the export script, run:

```sh
python omnivore-summary.py 
```

### Command line options

Instead of setting parameters in the script or via environment variables,
you can also pass them as options on the command line. You can show the
exact command line syntax by running the script with the  `--help` option.

## Data conversion script

### Prerequisites

In order to convert your Omnivore links to Wallabag, you need to export them
first using the function "Settings" - "Export Data" in the Omnivore web UI.

Then you need to unpack the downloaded zip file into a sub-directory name
"export" that should be in the same directory as the conversion script
`omnivore-to-wallabag.py`. You can also specify a different input directory
by changing the global variable `OMNIVORE_EXPORT_DIR` in the script.

### Running the script

Then simply run the script:

```sh
python omnivore-to-wallabag.py
```

It will produce an output file with the name `wallabag.json`. If your export
from Omnivore contains more than 500 links, then it will produce multiple
enumerated output files instead, because Wallabag might run out of memory
when the imported files are too huge. You can specify the batch size using
the global variable `BATCH_SIZE` in the script.

### Re-importing the data

Finally, import the JSON files generated by the script (in the correct order)
into Wallabag. You can find the import function in the web UI under
"My account" - "Import" - "Wallabag v2" - "Import contents" - "Upload file".

If you imported the wrong files and want to start from scratch, you can use
the function "Config" - "Reset area" - "Remove all entries" in Wallabag.

Note that the script currently does not convert highlights, just the links
and the content.
